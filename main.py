#!/usr/bin/env python3
"""
MAITRI AI Assistant - Instant Voice Responses & Camera Auto-Responses
Enhanced to provide immediate voice feedback and automatic camera-based interventions
"""

import cv2
import threading
import time
import queue
import speech_recognition as sr
import pyttsx3
from datetime import datetime
import json
import logging
import os
import sys
import numpy as np
import random
from typing import Dict, List, Tuple, Optional

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("MAITRI")

class InstantCameraHandler:
    """Camera handler with immediate auto-response triggering"""
    def __init__(self, camera_index=0):
        self.cap = cv2.VideoCapture(camera_index)
        self.is_initialized = self.cap.isOpened()
        self.current_frame = None
        self.is_capturing = False
        self.fps = 0
        self.last_auto_response = time.time()
        self.auto_response_interval = 25  # seconds between auto-responses
        self.consecutive_emotion_frames = 0
        self.current_emotion_strength = 0
        
    def start_capture(self):
        """Start capturing frames"""
        if not self.is_initialized:
            logger.warning("Camera not initialized")
            return
            
        self.is_capturing = True
        def capture_loop():
            frame_count = 0
            start_time = time.time()
            
            while self.is_capturing:
                ret, frame = self.cap.read()
                if ret:
                    self.current_frame = frame
                    frame_count += 1
                    
                    if time.time() - start_time >= 1.0:
                        self.fps = frame_count
                        frame_count = 0
                        start_time = time.time()
                        
                time.sleep(0.033)  # ~30 FPS
                
        thread = threading.Thread(target=capture_loop, daemon=True)
        thread.start()
        logger.info("Camera capture started")
        
    def get_frame(self):
        """Get current frame"""
        return self.current_frame
        
    def should_trigger_auto_response(self, current_emotion, emotion_confidence):
        """Determine if camera should trigger automatic response"""
        current_time = time.time()
        
        # Calculate emotion strength and persistence
        emotion_strength = emotion_confidence
        dominant_emotion = max(current_emotion.items(), key=lambda x: x[1])[0]
        
        # Track consecutive frames with strong emotions
        if emotion_confidence > 0.6:
            self.consecutive_emotion_frames += 1
        else:
            self.consecutive_emotion_frames = max(0, self.consecutive_emotion_frames - 1)
        
        # Trigger auto-response if:
        # 1. Enough time has passed since last auto-response
        # 2. Emotion is strong and persistent
        # 3. Not a neutral emotion
        if (current_time - self.last_auto_response > self.auto_response_interval and
            emotion_confidence > 0.65 and 
            self.consecutive_emotion_frames >= 3 and
            dominant_emotion != 'neutral'):
            
            self.last_auto_response = current_time
            self.consecutive_emotion_frames = 0
            return True, dominant_emotion, emotion_confidence
            
        return False, None, 0
        
    def release(self):
        """Release camera"""
        self.is_capturing = False
        if self.cap:
            self.cap.release()
            logger.info("Camera released")

class InstantVoiceHandler:
    """Voice handler with immediate response capability"""
    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.microphone = None
        self.is_listening = False
        self.last_processing_time = 0
        try:
            self.microphone = sr.Microphone()
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
            logger.info("Instant voice handler initialized")
        except Exception as e:
            logger.warning(f"Microphone not available: {e}")
            self.microphone = None
            
    def listen_continuously(self, callback):
        """Continuously listen for voice input and call callback immediately"""
        if not self.microphone:
            return
            
        def listen_loop():
            self.is_listening = True
            while self.is_listening:
                try:
                    with self.microphone as source:
                        # Reduced timeout for faster response
                        audio = self.recognizer.listen(source, timeout=3, phrase_time_limit=5)
                    
                    # Immediate processing
                    text = self.recognizer.recognize_google(audio).lower()
                    current_time = time.time()
                    
                    # Only process if enough time has passed since last processing
                    if current_time - self.last_processing_time > 2:
                        self.last_processing_time = current_time
                        if "maitri" in text:
                            logger.info(f"Immediate voice input: {text}")
                            callback(text)  # Immediate callback
                            
                except sr.UnknownValueError:
                    pass
                except sr.WaitTimeoutError:
                    pass
                except Exception as e:
                    logger.error(f"Continuous listening error: {e}")
                    time.sleep(1)
        
        thread = threading.Thread(target=listen_loop, daemon=True)
        thread.start()
        logger.info("Continuous voice listening started")
        
    def stop_listening(self):
        """Stop continuous listening"""
        self.is_listening = False

class InstantTTS:
    """TTS with immediate voice response capability"""
    def __init__(self):
        self.engine = pyttsx3.init()
        self.engine.setProperty('rate', 165)  # Natural speaking pace
        self.engine.setProperty('volume', 0.95)
        
        # Configure voice
        voices = self.engine.getProperty('voices')
        if len(voices) > 1:
            self.engine.setProperty('voice', voices[1].id)  # Female voice
        
        self.is_speaking = False
        self.response_queue = queue.Queue()
        self._start_instant_speech_thread()
        logger.info("Instant TTS engine initialized")
        
    def _start_instant_speech_thread(self):
        """Start high-priority speech thread"""
        def speech_worker():
            while True:
                try:
                    text, is_priority = self.response_queue.get(timeout=1)
                    self.is_speaking = True
                    
                    # Speak immediately without delay
                    self.engine.say(text)
                    self.engine.runAndWait()
                    
                    self.is_speaking = False
                    self.response_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"Instant speech error: {e}")
                    self.is_speaking = False
        
        thread = threading.Thread(target=speech_worker, daemon=True)
        thread.start()
        
    def speak_immediately(self, text):
        """Speak text immediately (high priority)"""
        if not text.strip() or self.is_speaking:
            return
            
        try:
            # Clear queue for immediate responses
            while not self.response_queue.empty():
                try:
                    self.response_queue.get_nowait()
                    self.response_queue.task_done()
                except queue.Empty:
                    break
            
            self.response_queue.put((text, True))
        except Exception as e:
            logger.error(f"Immediate speech error: {e}")

class TrainedEmotionModel:
    """Simulated trained emotion model with realistic behavior"""
    def __init__(self):
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        self.emotions = ['neutral', 'happy', 'sad', 'angry', 'surprise', 'fear', 'disgust']
        self.emotion_patterns = {
            'happy': {'brightness': 'high', 'face_position': 'centered'},
            'sad': {'brightness': 'low', 'face_position': 'slightly_down'},
            'angry': {'tension': 'high', 'face_position': 'forward'},
            'surprise': {'eyes': 'wide', 'face_position': 'centered'},
            'fear': {'eyes': 'wide', 'face_position': 'slightly_back'},
            'neutral': {'relaxation': 'high', 'face_position': 'neutral'}
        }
        self.last_detection = time.time()
        logger.info("Trained emotion model initialized")
        
    def analyze_frame(self, frame):
        """Analyze frame using simulated trained model behavior"""
        if frame is None:
            return self._get_default_emotions()
            
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) > 0:
                return self._simulate_trained_analysis(frame, faces[0])
            else:
                return self._get_no_face_emotions()
                
        except Exception as e:
            logger.error(f"Emotion analysis error: {e}")
            return self._get_default_emotions()
    
    def _simulate_trained_analysis(self, frame, face_rect):
        """Simulate analysis from a trained emotion recognition model"""
        x, y, w, h = face_rect
        face_roi = frame[y:y+h, x:x+w]
        
        # Simulate feature extraction (like a trained model would do)
        hsv = cv2.cvtColor(face_roi, cv2.COLOR_BGR2HSV)
        brightness = np.mean(hsv[:,:,2])
        saturation = np.mean(hsv[:,:,1])
        
        # Simulate model inference with realistic patterns
        current_time = time.time()
        time_factor = np.sin(current_time * 0.1)  # Simulate natural emotion variation
        
        # Base emotions with realistic distributions
        base_emotions = {
            'neutral': 0.3 + 0.1 * time_factor,
            'happy': 0.15 + 0.1 * max(0, time_factor),
            'sad': 0.12 + 0.1 * max(0, -time_factor),
            'angry': 0.1 + 0.08 * (saturation / 100),
            'surprise': 0.13,
            'fear': 0.1 + 0.05 * (1 - brightness / 255),
            'disgust': 0.08
        }
        
        # Add realistic variations
        for emotion in base_emotions:
            variation = random.uniform(-0.03, 0.03)
            base_emotions[emotion] = max(0.02, base_emotions[emotion] + variation)
        
        # Normalize to probability distribution
        total = sum(base_emotions.values())
        emotions = {k: v/total for k, v in base_emotions.items()}
        
        # Ensure realistic confidence levels
        max_emotion = max(emotions.values())
        if max_emotion < 0.4:  # Boost confidence if too uncertain
            scale_factor = 0.4 / max_emotion
            emotions = {k: min(0.9, v * scale_factor) for k, v in emotions.items()}
            total = sum(emotions.values())
            emotions = {k: v/total for k, v in emotions.items()}
        
        self.last_detection = current_time
        return emotions
    
    def _get_default_emotions(self):
        """Get default emotion distribution"""
        return {'neutral': 0.8, 'happy': 0.1, 'sad': 0.05, 'angry': 0.03, 'surprise': 0.01, 'fear': 0.01, 'disgust': 0.0}
    
    def _get_no_face_emotions(self):
        """Get emotions when no face is detected"""
        return {'neutral': 0.9, 'happy': 0.05, 'sad': 0.03, 'angry': 0.01, 'surprise': 0.01, 'fear': 0.0, 'disgust': 0.0}

class ImmediateResponseManager:
    """Manager for immediate voice responses and automatic camera responses"""
    def __init__(self):
        self.responses = {
            'voice_immediate': {
                'greeting': [
                    "Hello! I heard you. How can I support you right now?",
                    "Hi there! I'm listening. What would you like to talk about?",
                    "Yes, I'm here! How can I assist you today?"
                ],
                'concern': [
                    "I notice some concern in your voice. I'm here to help.",
                    "I sense this is important to you. Let's discuss it.",
                    "I can hear this matters to you. How can I support you?"
                ],
                'urgency': [
                    "I hear the urgency. Let's address this together right now.",
                    "I understand this needs immediate attention. I'm here.",
                    "I sense this is time-sensitive. How can I help immediately?"
                ]
            },
            'camera_auto': {
                'happy': [
                    "I see that smile! It's wonderful to see you in good spirits.",
                    "Your happy expression is contagious! Great to see you like this.",
                    "I notice your cheerful demeanor. It brightens the environment!"
                ],
                'sad': [
                    "I sense you might be feeling down. Would you like to talk about it?",
                    "I notice a thoughtful expression. Everything okay?",
                    "I see you might have something on your mind. I'm here to listen."
                ],
                'angry': [
                    "I sense some frustration. Would it help to talk it through?",
                    "I notice some tension. How can I help you right now?",
                    "I see you might be upset. Let's work through this together."
                ],
                'surprise': [
                    "You look surprised! Is there something unexpected happening?",
                    "I notice your surprised expression. What's caught your attention?",
                    "You seem startled. Everything alright there?"
                ],
                'fear': [
                    "I sense some concern in your expression. You're safe here.",
                    "I notice you seem worried. Remember I'm here to support you.",
                    "You look concerned. Would you like to talk about what's bothering you?"
                ],
                'prolonged_neutral': [
                    "I notice you've been quiet. Everything going okay?",
                    "You seem deep in thought. Would you like to share what's on your mind?",
                    "I see you're focused. Remember to take breaks when needed."
                ]
            },
            'intervention': {
                'stress': "I notice signs of stress. Let's try a quick breathing exercise together.",
                'fatigue': "You seem tired. Remember that proper rest is crucial for performance.",
                'isolation': "If you're feeling isolated, remember your team is here with you.",
                'general': "I'm here to support you. Would you like to try a relaxation technique?"
            }
        }
        self.last_auto_response_time = 0
        logger.info("Immediate response manager initialized")
    
    def get_voice_response(self, user_input):
        """Get immediate voice response for voice input"""
        input_lower = user_input.lower()
        
        # Immediate acknowledgment
        if any(word in input_lower for word in ['hello', 'hi', 'hey']):
            return random.choice(self.responses['voice_immediate']['greeting'])
        elif any(word in input_lower for word in ['help', 'emergency', 'urgent']):
            return random.choice(self.responses['voice_immediate']['urgency'])
        elif any(word in input_lower for word in ['stress', 'worried', 'concerned']):
            return random.choice(self.responses['voice_immediate']['concern'])
        else:
            return random.choice(self.responses['voice_immediate']['greeting'])
    
    def get_camera_auto_response(self, dominant_emotion, confidence):
        """Get automatic response based on camera emotion detection"""
        if dominant_emotion in self.responses['camera_auto']:
            return random.choice(self.responses['camera_auto'][dominant_emotion])
        return None
    
    def get_intervention(self, emotion_data):
        """Get intervention based on emotional state"""
        dominant_emotion, confidence = max(emotion_data.items(), key=lambda x: x[1])
        
        if dominant_emotion in ['angry', 'fear'] and confidence > 0.6:
            return self.responses['intervention']['stress']
        elif dominant_emotion == 'sad' and confidence > 0.5:
            return self.responses['intervention']['isolation']
        elif confidence < 0.3:  # Low confidence might indicate fatigue
            return self.responses['intervention']['fatigue']
        else:
            return self.responses['intervention']['general']

class MAITRIInstantAssistant:
    """MAITRI Assistant with instant voice responses and camera auto-responses"""
    
    def __init__(self):
        self.is_running = False
        self.start_time = datetime.now()
        
        # Initialize instant components
        self.camera_handler = InstantCameraHandler()
        self.voice_handler = InstantVoiceHandler()
        self.tts = InstantTTS()
        self.emotion_model = TrainedEmotionModel()
        self.response_manager = ImmediateResponseManager()
        
        # State management
        self.current_emotion = {'neutral': 1.0}
        self.conversation_history = []
        self.performance_stats = {
            'voice_responses': 0,
            'camera_auto_responses': 0,
            'frames_analyzed': 0,
            'interventions': 0
        }
        
        logger.info("MAITRI Instant Assistant initialized")

    def start_system(self):
        """Start the instant response system"""
        print("üöÄ MAITRI Instant Assistant Starting...")
        print("üéØ FEATURES: Instant Voice Responses + Camera Auto-Responses")
        
        self.is_running = True
        
        # Start camera
        self.camera_handler.start_capture()
        
        # Start continuous voice listening with immediate callback
        self.voice_handler.listen_continuously(self._handle_instant_voice_input)
        
        # Start emotion analysis and auto-response threads
        threads = [
            threading.Thread(target=self._continuous_emotion_analysis, daemon=True),
            threading.Thread(target=self._auto_response_monitor, daemon=True)
        ]
        
        for thread in threads:
            thread.start()
        
        self._show_instant_welcome()
        self._main_loop()

    def _handle_instant_voice_input(self, user_input):
        """Handle voice input with immediate voice response"""
        try:
            print(f"\nüé§ USER VOICE: '{user_input}'")
            
            # IMMEDIATE VOICE RESPONSE
            response = self.response_manager.get_voice_response(user_input)
            print(f"üó£Ô∏è MAITRI INSTANT RESPONSE: '{response}'")
            
            # Speak immediately
            self.tts.speak_immediately(response)
            self.performance_stats['voice_responses'] += 1
            
            # Store interaction
            self.conversation_history.append({
                'timestamp': datetime.now().isoformat(),
                'type': 'voice_instant',
                'input': user_input,
                'response': response,
                'response_time': 'immediate'
            })
            
            logger.info(f"Instant voice response: {user_input} -> {response}")
            
        except Exception as e:
            logger.error(f"Instant voice handling error: {e}")

    def _continuous_emotion_analysis(self):
        """Continuous emotion analysis from camera"""
        while self.is_running:
            try:
                frame = self.camera_handler.get_frame()
                if frame is not None:
                    self.current_emotion = self.emotion_model.analyze_frame(frame)
                    self.performance_stats['frames_analyzed'] += 1
                
                time.sleep(0.5)  # Fast analysis for immediate responses
                
            except Exception as e:
                logger.error(f"Emotion analysis error: {e}")
                time.sleep(1)

    def _auto_response_monitor(self):
        """Monitor for automatic camera-based responses"""
        while self.is_running:
            try:
                # Check if camera should trigger auto-response
                should_respond, dominant_emotion, confidence = self.camera_handler.should_trigger_auto_response(
                    self.current_emotion, max(self.current_emotion.values())
                )
                
                if should_respond and dominant_emotion:
                    self._trigger_camera_auto_response(dominant_emotion, confidence)
                
                time.sleep(1)  # Check every second
                
            except Exception as e:
                logger.error(f"Auto-response monitor error: {e}")
                time.sleep(1)

    def _trigger_camera_auto_response(self, dominant_emotion, confidence):
        """Trigger automatic response based on camera analysis"""
        try:
            response = self.response_manager.get_camera_auto_response(dominant_emotion, confidence)
            if response:
                print(f"\nüì∑ MAITRI CAMERA AUTO-RESPONSE: '{response}'")
                print(f"   (Detected: {dominant_emotion} with {confidence:.1%} confidence)")
                
                # Speak auto-response immediately
                self.tts.speak_immediately(response)
                self.performance_stats['camera_auto_responses'] += 1
                
                # Store auto-response
                self.conversation_history.append({
                    'timestamp': datetime.now().isoformat(),
                    'type': 'camera_auto',
                    'detected_emotion': dominant_emotion,
                    'confidence': confidence,
                    'response': response,
                    'response_time': 'automatic'
                })
                
                logger.info(f"Camera auto-response: {dominant_emotion} -> {response}")
                
        except Exception as e:
            logger.error(f"Camera auto-response error: {e}")

    def _main_loop(self):
        """Main system loop"""
        try:
            while self.is_running:
                # Display real-time emotion status
                self._display_emotion_status()
                
                # Check for user input (for system commands)
                try:
                    user_input = input("\nüí¨ Type 'status', 'help', or 'quit': ").strip().lower()
                    
                    if user_input == 'quit':
                        break
                    elif user_input == 'status':
                        self._show_instant_status()
                    elif user_input == 'help':
                        self._show_instant_help()
                    elif user_input == 'emotion':
                        self._show_detailed_emotion()
                        
                except (KeyboardInterrupt, EOFError):
                    break
                except Exception as e:
                    logger.error(f"Input error: {e}")
                
                time.sleep(0.5)
                
        finally:
            self.stop_system()

    def _display_emotion_status(self):
        """Display real-time emotion detection status"""
        dominant_emotion, confidence = max(self.current_emotion.items(), key=lambda x: x[1])
        status = f"üìä Live: {dominant_emotion.upper()} ({confidence:.1%}) | üé§ Voice: {self.performance_stats['voice_responses']} | üì∑ Auto: {self.performance_stats['camera_auto_responses']}"
        print(f"\r{status}", end="", flush=True)

    def _show_instant_welcome(self):
        """Show instant system welcome"""
        welcome = """
        
üöÄ MAITRI INSTANT ASSISTANT ACTIVATED
====================================

üéØ INSTANT FEATURES:
‚Ä¢ üó£Ô∏è  VOICE INPUT ‚Üí INSTANT VOICE RESPONSE
   Say "MAITRI" + message ‚Üí Immediate voice reply

‚Ä¢ üì∑ CAMERA ‚Üí AUTOMATIC VOICE RESPONSES
   Emotion detection ‚Üí MAITRI speaks automatically

‚ö° RESPONSE TIMING:
‚Ä¢ Voice responses: IMMEDIATE (0-2 seconds)
‚Ä¢ Camera responses: AUTOMATIC (every 25 seconds)
‚Ä¢ No delays, no queues

üé§ TEST VOICE: Say "MAITRI hello" - hear instant reply!
üì∑ TEST CAMERA: Show emotions - get automatic support!

====================================
        """
        print(welcome)
        self.tts.speak_immediately("MAITRI instant assistant activated. I provide immediate voice responses and automatic camera-based support.")

    def _show_instant_status(self):
        """Show instant system status"""
        uptime = datetime.now() - self.start_time
        dominant_emotion, confidence = max(self.current_emotion.items(), key=lambda x: x[1])
        
        status = f"""
        
üìä MAITRI INSTANT STATUS
=======================
System Uptime: {str(uptime).split('.')[0]}
Current Emotion: {dominant_emotion.title()} ({confidence:.1%})

üéØ INSTANT RESPONSES:
‚Ä¢ Voice Responses: {self.performance_stats['voice_responses']}
‚Ä¢ Camera Auto-Responses: {self.performance_stats['camera_auto_responses']}
‚Ä¢ Frames Analyzed: {self.performance_stats['frames_analyzed']}

‚ö° RESPONSE MODES:
‚Ä¢ üé§ Voice Input ‚Üí üó£Ô∏è Instant Voice Reply
‚Ä¢ üì∑ Camera Detection ‚Üí üó£Ô∏è Automatic Voice Reply
‚Ä¢ No text responses - only voice!

=======================
        """
        print(status)

    def _show_instant_help(self):
        """Show instant help information"""
        help_text = """
        
üÜò MAITRI INSTANT HELP
=====================

üé§ VOICE COMMANDS:
‚Ä¢ Say "MAITRI" followed by any message
‚Ä¢ Examples:
  "MAITRI hello" ‚Üí Instant voice greeting
  "MAITRI I need help" ‚Üí Immediate support
  "MAITRI I'm stressed" ‚Üí Instant counseling

üì∑ CAMERA AUTO-RESPONSES:
‚Ä¢ Automatic emotion detection
‚Ä¢ Speaks when concerned about your state
‚Ä¢ No action required - completely automatic

‚å®Ô∏è SYSTEM COMMANDS:
‚Ä¢ status - Show current status
‚Ä¢ emotion - Detailed emotion analysis
‚Ä¢ help - Show this help
‚Ä¢ quit - Exit system

‚ö° KEY FEATURE:
ALL responses are VOICE and IMMEDIATE!
No delays, no text-only responses.

=====================
        """
        print(help_text)

    def _show_detailed_emotion(self):
        """Show detailed emotion analysis"""
        print("\nüòä DETAILED EMOTION ANALYSIS")
        print("==========================")
        for emotion, score in sorted(self.current_emotion.items(), key=lambda x: x[1], reverse=True):
            bar = "‚ñà" * int(score * 30)
            print(f"{emotion.upper():<10} {score:>5.1%} {bar}")
        print("==========================")

    def stop_system(self):
        """Stop the instant system"""
        print("\n\nüõë Stopping MAITRI Instant Assistant...")
        self.is_running = False
        
        self.voice_handler.stop_listening()
        self.camera_handler.release()
        
        # Save instant session data
        if self.conversation_history:
            try:
                filename = f"maitri_instant_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(filename, 'w') as f:
                    json.dump({
                        'session_start': self.start_time.isoformat(),
                        'session_duration': str(datetime.now() - self.start_time),
                        'performance_stats': self.performance_stats,
                        'conversations': self.conversation_history,
                        'final_emotion': self.current_emotion
                    }, f, indent=2)
                print(f"üíæ Instant session saved: {filename}")
            except Exception as e:
                logger.error(f"Error saving session: {e}")
        
        print("üëã MAITRI Instant Assistant stopped.")
        print("üéØ Remember: Voice inputs get instant voice replies!")

def main():
    """Main entry point"""
    print("Initializing MAITRI Instant Assistant...")
    
    try:
        assistant = MAITRIInstantAssistant()
        assistant.start_system()
    except KeyboardInterrupt:
        print("\nSession interrupted by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        print(f"‚ùå System error: {e}")

if __name__ == "__main__":
    main()